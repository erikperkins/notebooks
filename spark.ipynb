{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88202d91-5fe8-4126-9195-106d0bf59b5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T14:12:10.239070Z",
     "iopub.status.busy": "2025-09-05T14:12:10.238853Z",
     "iopub.status.idle": "2025-09-05T14:12:34.033750Z",
     "shell.execute_reply": "2025-09-05T14:12:34.032899Z",
     "shell.execute_reply.started": "2025-09-05T14:12:10.239056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Spark 4.0.0 on Python 3.13.5 | packaged by conda-forge | (main, Jun 16 2025, 08:27:50) [GCC 13.3.0]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark\n",
    "import socket\n",
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(f\"Running Spark {pyspark.__version__} on Python {sys.version}\")\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"spark-jupyterhub\")\n",
    "    .master(\"k8s://https://kubernetes.default.svc.cluster.local\")\n",
    "    .config(\"spark.kubernetes.container.image\", \"erikperkins/spark:4.0.0\")\n",
    "    .config(\"spark.kubernetes.container.image.pullPolicy\", \"Always\")\n",
    "    .config(\"spark.kubernetes.namespace\", \"jupyterhub\")\n",
    "    .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\", \"singleuser\")\n",
    "    .config(\"spark.kubernetes.authenticate.serviceAccountName\", \"singleuser\")\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.4.1,com.amazonaws:aws-java-sdk:1.12.788,software.amazon.awssdk:bundle:2.24.6\")\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", os.environ[\"AWS_ACCESS_KEY_ID\"])\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", os.environ[\"AWS_SECRET_ACCESS_KEY\"])\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint.region\", \"us-east-1\") \n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    .config(\"spark.driver.host\", socket.gethostbyname(socket.gethostname()))\n",
    "    .config(\"spark.driver.port\", 2222)\n",
    "    .config(\"spark.driver.blockManager.port\", 7777)\n",
    "    .config(\"spark.driver.bindAddress\", \"0.0.0.0\")\n",
    "    .config(\"spark.executor.instances\", 2)\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4490b1c1-ffd0-4d38-9eea-d087898ac9bc",
   "metadata": {},
   "source": [
    "---\n",
    "#### S3 Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a49f6fb-65dd-47f9-a22d-034acf2907de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T14:12:37.900235Z",
     "iopub.status.busy": "2025-09-05T14:12:37.899902Z",
     "iopub.status.idle": "2025-09-05T14:12:49.193746Z",
     "shell.execute_reply": "2025-09-05T14:12:49.193066Z",
     "shell.execute_reply.started": "2025-09-05T14:12:37.900215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|VendorID|avg(passenger_count)|\n",
      "+--------+--------------------+\n",
      "|       1|  1.1323442533986385|\n",
      "|       7|  1.2969443342111908|\n",
      "|       2|  1.3644769487032042|\n",
      "|       6|                NULL|\n",
      "+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "df = spark.read.parquet(\"s3a://minikube-jupyterhub-data/*.parquet\")\n",
    "df.groupBy(\"VendorID\").agg({\"passenger_count\": \"mean\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f784137f-2db6-472c-9d3f-7a84e2535a43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T14:12:51.778102Z",
     "iopub.status.busy": "2025-09-05T14:12:51.777881Z",
     "iopub.status.idle": "2025-09-05T14:12:54.294844Z",
     "shell.execute_reply": "2025-09-05T14:12:54.294236Z",
     "shell.execute_reply.started": "2025-09-05T14:12:51.778087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|slen|\n",
      "+----+\n",
      "|   4|\n",
      "|   4|\n",
      "|   4|\n",
      "+----+\n",
      "only showing top 3 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "slen = udf(lambda s: len(str(s)))\n",
    "\n",
    "df.select(slen(\"fare_amount\").alias(\"slen\")).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1e91b2-5fa6-43a9-91ff-bffcc9632c16",
   "metadata": {},
   "source": [
    "---\n",
    "#### NDJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3195ae83-8efc-4cea-8314-02f46467b429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Spark 4.0.0 on Python 3.13.5 | packaged by conda-forge | (main, Jun 16 2025, 08:27:50) [GCC 13.3.0]\n",
      "root\n",
      " |-- apiVersion: string (nullable = true)\n",
      " |-- kind: string (nullable = true)\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- namespace: string (nullable = true)\n",
      " |    |-- labels: struct (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      "\n",
      "+----------+----------+--------------------+\n",
      "|apiVersion|      kind|            metadata|\n",
      "+----------+----------+--------------------+\n",
      "|        v1| Namespace|{snowflake, NULL,...|\n",
      "|   apps/v1|Deployment|{snowflake, snowf...|\n",
      "+----------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yaml_schema = \"\"\"\n",
    "fields:\n",
    "- metadata: {}\n",
    "  name: apiVersion\n",
    "  nullable: true\n",
    "  type: string\n",
    "- metadata: {}\n",
    "  name: kind\n",
    "  nullable: true\n",
    "  type: string\n",
    "- metadata: {}\n",
    "  name: metadata\n",
    "  nullable: true\n",
    "  type:\n",
    "    fields:\n",
    "    - metadata: {}\n",
    "      name: name\n",
    "      nullable: true\n",
    "      type: string\n",
    "    - metadata: {}\n",
    "      name: namespace\n",
    "      nullable: true\n",
    "      type: string\n",
    "    - metadata: {}\n",
    "      name: labels\n",
    "      nullable: true\n",
    "      type:\n",
    "        fields:\n",
    "        - metadata: {}\n",
    "          name: name\n",
    "          nullable: true\n",
    "          type: string\n",
    "        type: struct\n",
    "    type: struct\n",
    "type: struct\n",
    "\"\"\"\n",
    "\n",
    "schema = StructType.fromJson(yaml.safe_load(yaml_schema))\n",
    "print(schema.treeString())\n",
    "\n",
    "df = spark.read.schema(schema).json(\"s3a://minikube-jupyterhub-data/*.ndjson\")\n",
    "df.filter(F.col(\"metadata.name\") == \"snowflake\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7527b6f8-7096-4e31-a4b7-24f358c78c71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
