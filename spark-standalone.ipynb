{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88202d91-5fe8-4126-9195-106d0bf59b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Spark 4.0.0 on Python 3.13.5 | packaged by conda-forge | (main, Jun 16 2025, 08:27:50) [GCC 13.3.0]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark\n",
    "import socket\n",
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "\n",
    "REGION = \"us-east-1\"\n",
    "BUCKET = \"minikube-jupyterhub-data\"\n",
    "\n",
    "print(f\"Running Spark {pyspark.__version__} on Python {sys.version}\")\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"spark-jupyterhub\")\n",
    "    .master(\"spark://master.spark.svc.cluster.local:7077\")\n",
    "    .config(\"spark.driver.host\", socket.gethostbyname(socket.gethostname()))\n",
    "    .config(\"spark.driver.port\", 2222)\n",
    "    .config(\"spark.driver.blockManager.port\", 7777)\n",
    "    .config(\"spark.driver.bindAddress\", \"0.0.0.0\")\n",
    "    .config(\"spark.jars\", \"/home/jovan/hadoop-aws-3.4.1.jar,/home/jovyan/bundle-2.24.6.jar,/home/jovyan/openssl_wildfly-openssl-1.1.3.Final.jar\")\n",
    "    .config(\"spark.extraListeners\", \"sparkmonitor.listener.JupyterSparkMonitorListener\")\n",
    "    .config(\"spark.driver.extraClassPath\", \"/opt/conda/lib/python3.13/site-packages/sparkmonitor/listener_2.13.jar\")\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.fallback.enabled\", \"true\")\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", os.environ[\"AWS_ACCESS_KEY_ID\"])\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", os.environ[\"AWS_SECRET_ACCESS_KEY\"])\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint.region\", REGION)\n",
    "    .config(\"spark.ui.reverseProxy\", \"true\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1e91b2-5fa6-43a9-91ff-bffcc9632c16",
   "metadata": {},
   "source": [
    "---\n",
    "#### NDJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3195ae83-8efc-4cea-8314-02f46467b429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+\n",
      "|apiVersion|      kind|            metadata|\n",
      "+----------+----------+--------------------+\n",
      "|        v1| Namespace|{snowflake, NULL,...|\n",
      "|   apps/v1|Deployment|{snowflake, snowf...|\n",
      "+----------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yaml_schema = \"\"\"\n",
    "fields:\n",
    "- metadata: {}\n",
    "  name: apiVersion\n",
    "  nullable: true\n",
    "  type: string\n",
    "- metadata: {}\n",
    "  name: kind\n",
    "  nullable: true\n",
    "  type: string\n",
    "- metadata: {}\n",
    "  name: metadata\n",
    "  nullable: true\n",
    "  type:\n",
    "    fields:\n",
    "    - metadata: {}\n",
    "      name: name\n",
    "      nullable: true\n",
    "      type: string\n",
    "    - metadata: {}\n",
    "      name: namespace\n",
    "      nullable: true\n",
    "      type: string\n",
    "    - metadata: {}\n",
    "      name: labels\n",
    "      nullable: true\n",
    "      type:\n",
    "        fields:\n",
    "        - metadata: {}\n",
    "          name: name\n",
    "          nullable: true\n",
    "          type: string\n",
    "        type: struct\n",
    "    type: struct\n",
    "type: struct\n",
    "\"\"\"\n",
    "\n",
    "schema = StructType.fromJson(yaml.safe_load(yaml_schema))\n",
    "df = spark.read.schema(schema).json(f\"s3a://{BUCKET}/*.ndjson.gz\")\n",
    "df.filter(F.col(\"metadata.name\") == \"snowflake\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4490b1c1-ffd0-4d38-9eea-d087898ac9bc",
   "metadata": {},
   "source": [
    "---\n",
    "#### S3 Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a49f6fb-65dd-47f9-a22d-034acf2907de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|VendorID|avg(passenger_count)|\n",
      "+--------+--------------------+\n",
      "|       1|  1.1323442533986385|\n",
      "|       7|  1.2969443342111908|\n",
      "|       2|  1.3644769487032042|\n",
      "|       6|                NULL|\n",
      "+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "df = spark.read.parquet(f\"s3a://{BUCKET}/*.parquet\")\n",
    "df.groupBy(\"VendorID\").agg({\"passenger_count\": \"mean\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f784137f-2db6-472c-9d3f-7a84e2535a43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|slen|\n",
      "+----+\n",
      "|   4|\n",
      "|   4|\n",
      "|   4|\n",
      "+----+\n",
      "only showing top 3 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "slen = udf(lambda s: len(str(s)))\n",
    "\n",
    "df.select(slen(\"fare_amount\").alias(\"slen\")).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dcbaef-06a4-45d7-8935-4415bac4eaec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
